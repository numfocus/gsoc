Result-aggregation server for the installation-test scripts 
============================================================== 
 
Contents 
-------------- 
1. **Abstract** 
2. **Technical Details** 
3. **Schedule of deliverables** 
4. **Future Works** 
5. **Open Source Development Experience** 
6. **Academic Experience** 
7. **Why this Project ?** 
 
## Abstract 
Software Carpentry has been teaching researchers in science, engineering, medicine, and related disciplines the computing skills they need to get more done in less time and with less pain. Several workshops are held in which students are required to setup their system by installing necessary packages.

Currently software carpentry provides the [installation-test scripts](https://github.com/wking/swc-setup-installation-test) so that, students can check whether they've successfully installed all software required during the workshop. But the results generated by the scripts are not collected anywhere.

In this project a server is to be written for storing results of installation-testing scripts, and also enhancing the testing scripts by adding an option for users to collect results and send them to the server. It will help in figuring out what all problems students usually face in installations ,and also the packages which need to be deprecated in future.
 
## Technical Details 
I am breaking it down to several steps in which this project has to be approached : 
### System Information collection 
The installation-test script needs to be modified to retrieve some useful information about the user and the environment in which they are running the installation-test-script. 
* Operating System information, which includes : 
  * System information ( Linux / windows / Mac etc ) 
  * Distribution information ( redhat / debian / fedora etc) 
  * Machine Architecture information ( x86 / x64 ) 
  * Complete platform information 
  * Uname ( System info like kernel-name, kernel-version etc ) 
  * Version ( Systemâ€™s release version ) 
  * Machine information ( Machine type, e.g. 'i386' )
  * Python Version
  
All of this information can be retrieved by using a library in python called `Platform`, code of which I wrote in my [demo](https://github.com/prerit2010/DemoAPI) application. The code snippet : 
```python 
import platform 
 
system_dist = str(platform.dist()) 
system = platform.system() 
machine = platform.machine() 
system_platform = platform.platform() 
uname = platform.uname() 
version = platform.version() 
python_version = platform.python_version() 
``` 

Sample of output generated in case of Ubuntu : 
``` 
Python version: ['2.7.3 (default, Sep 26 2012, 21:51:14) ', '[GCC 4.7.2]'] 
dist: ('Ubuntu', '12.10', 'quantal') 
linux_distribution: ('Ubuntu', '12.10', 'quantal') 
system: Linux 
machine: x86_64 
platform: Linux-3.5.0-22-generic-x86_64-with-Ubuntu-12.10-quantal 
uname: ('Linux', 'stijn-W150HRM', '3.5.0-22-generic', '#34-Ubuntu SMP Tue Jan 8 21:47:00 UTC 2013', 'x86_64', 'x86_64') 
version: #34-Ubuntu SMP Tue Jan 8 21:47:00 UTC 2013 
``` 
Some or most of these information are being retrieved in the [installation-test-scripts](https://github.com/wking/swc-setup-installation-test).
### Success/Failure of packages information collection 
* **Successful Installs** list is already provided by the script. A list `successes` contains both checker and the version. Server can just grab the full name by `checker.full_name()` and `version` of the successfully installed packages. 
* **Failed Checks** list is also provided by the script with the name of the package, error description and also the cause for some cases. e.g. : 
```
check for IPython script (ipython) failed: ( Name : IPython script (ipython) )
  errors finding IPython script (ipython) version  <-- Description
causes:
  check for IPython script (ipython) failed:
    could not find 'ipython' executable  <-- Cause
```
### Other information 
* Diagnostic information 
* Timestamp 
* User email address
* Workshop Id

### Server and API
Following are the components of this project :
* API
* Database
* Client (installation-test-scripts)
* Admin Console (Front end)

The interation between components shall take place as depicted below :
![flow](http://i.imgur.com/ASFyavS.png)

### API
An API is to be developed to store the results generated by the test script. I shall be using Python's web framework [FLASK](http://flask.pocoo.org/) for this purpose. Reason being, flask is a [microframework](https://en.wikipedia.org/wiki/Microframework) which is incredibly flexible and easily scalable. Very little initial code is needed for small projects, and which can be ramped up with relative ease in case the project becomes complex. This is in contrast to something like the Django framework, which, despite its strengths, depends on convention rather than flexibility. So, flask is the most suitable option as it seems. 

This would involve : 
* **Modification of the installation-test-scrips** and giving the user an option to send the data to the server by making a [POST](https://en.wikipedia.org/wiki/POST_(HTTP)) request to the API endpoint with payload of all the information collected. Code Snippet : 
```python
import requests 
 
headers = { 
    "Content-Type": "application/json", 
} 
HOST = "http://127.0.0.1:5000" 
os_end_point = "/system_info/" 
data = {"system_dist" : system_dist , "version": version} 
uri = '{}{}'.format(HOST, os_end_point)
response = requests.post(uri, data=json.dumps(data), headers=headers) 
``` 
* This API will follow the [REST](https://en.wikipedia.org/wiki/Representational_state_transfer) standard, and all the data shall be sent in [JSON](http://www.json.org/) to the API. 
 
* Setting up the **Database**. As mentioned in the description of the idea, [SQLite](https://www.sqlite.org/) is preferred, but it suffers some problems in case 40-50 people send the data simultaneously. After going through the comparison given [here](https://www.digitalocean.com/community/tutorials/sqlite-vs-mysql-vs-postgresql-a-comparison-of-relational-database-management-systems), I would personally prefer [MySQL](https://www.mysql.com/) or [PostgreSQL](http://www.postgresql.org/) in this project. But that can be decided later as per the discussion with mentors. All interactions with the database shall be done using **SQLAlchemy** and **Alembic**.
 
* Modelling the information collected at the client end. There shall be Tables in the database for user_system_info, successful installs and failed installs. All shall be referenced with a **unique id**, which will be used as a **foreign key** in all the tables, to identify a particular user associated with that entry in DB. 
  

### Database Schema
* User shall be prompted to enter the `workshop_id` and `email_id` before sending the data to the server, as it would enable the server to associate each result with the workshop, and summarize conclusions that are workshop specific and also overall.
* Combination of `workshop_id` and `email_id` would give us a unique id per user per workshop, and thus would prevent duplicate entries in the table for the same student attending the same workshop.
* Everytime a call is made to the API, it will first check whether an entry is already there for particular `workshop_id` and `email_id`. If yes, UPDATE query shall be made instead of INSERT query.
* Initial Proposed schema :

![diagram](http://i.imgur.com/vTTrkDP.png)

* I suggest using [SQLAlchemy](http://www.sqlalchemy.org/) for querying and handling the database. It has several advantages over using traditional SQL connectors, such as producing code, which is more readable, easier to maintain, less prone to errors and less vulnerable to attacks. SQLAlchemy does not consider a database as just a set of tables, rows and columns, but rather as a relational algebra engine. Writing complex raw queries can lead to difficult to maintain code. Any schematic changes in the database can be easily taken care of using SQLAlchemy. Sample code snippet :
```python
import os
 
from sqlalchemy import Column, DateTime, String, Integer, func
from sqlalchemy.orm import relationship, backref
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
 
Base = declarative_base()

class UserSystemInfo(Base):
    __tablename__ = 'user_system_info'
    user_id = Column(Integer, primary_key=True)
    system_dist = Column(String)
    uname  = Column(String)
    version = Column(String)
    system_dist = Column(String)
    system = Column(String)
    machine = Column(String)
    system_platform = Column(String) 
    uname = Column(String)
    version = Column(String)
    python_version = Column(String)
    workshop_id = Column(String)
    email_id = Column(String)
    Create_time = Column(DateTime, default=func.now())
 
class SuccessfulInstalls(Base):
    __tablename__ = 'successful_installs'
    success_id = Column(Integer, primary_key=True)
    name = Column(String)
    Version = Column(String)
    user_id = Column(
        Integer,
        ForeignKey('user_system_info.user_id', ondelete='CASCADE'),
        nullable=False,
    )
    Create_time = Column(DateTime, default=func.now())
    user_system_info = relationship(
        UserSystemInfo,
        backref=backref('successful_installs',
                         uselist=True,
                         cascade='delete,all'))

Class FailedInstalls(Base):
    __tablename__ = 'failed_installs'
    fail_id = Column(Integer, primary_key=True)
    name = Column(String)
    version = Column(String)
    error_description = Column(String)
    error_cause = Column(String)
    user_id = Column(
        Integer,
        ForeignKey('user_system_info.user_id', ondelete='CASCADE'),
        nullable=False,
    )
    Create_time = Column(DateTime, default=func.now())
    user_system_info = relationship(
        UserSystemInfo,
        backref=backref('failed_installs',
                         uselist=True,
                         cascade='delete,all'))
 
db_name = 'installation_server.sqlite'
if os.path.exists(db_name):
    os.remove(db_name)
 
engine = create_engine('sqlite:///' + db_name)
 
session = sessionmaker()
session.configure(bind=engine)
Base.metadata.create_all(engine)
```
### Database migration

There are several ways to perform database migration, like SQLalchemy-migrate, Flask-migrate, [Alembic](https://alembic.readthedocs.org/en/latest/), which is specifically built for SQLAlchemy. For this I plan to use [Flask-Migrate](https://flask-migrate.readthedocs.org/en/latest/), a migration tool based on alembic.
Code Snippet :
```python
from flask import Flask
from flask.ext.sqlalchemy import SQLAlchemy
from flask.ext.script import Manager
from flask.ext.migrate import Migrate, MigrateCommand

app = Flask(__name__)
app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///app.db'

db = SQLAlchemy(app)
migrate = Migrate(app, db)

manager = Manager(app)
manager.add_command('db', MigrateCommand)

if __name__ == '__main__':
    manager.run()
```

### Frontend
* For the Server Administrator, a basic **frontend** can be developed for them to manage and analyse the results, e.g. 
 * Common install problems faced in a particular workshop 
 * Common install problems faced by students overall. 
 * Which version of package is most prone to errors, etc. 
  
* The front end can be developed using simple HTML, CSS, [Bootstrap](http://getbootstrap.com/) , Javascript.  
* For the greater good, some plots can be generated by extracting useful information about the failures. This can be done using [Plotly](https://plot.ly/). This will provide better understanding by visualization. Code Snippet :
```python
import plotly.plotly as py
import plotly.graph_objs as go

data = [
            go.Bar(
                x=['Ubuntu' , 'Redhat' , 'Fedora'],
                y=[30 , 20 , 40] ,
            )
        ]
        file_name = "filename"
        plot_url = py.plot(data, filename=file_name , auto_open=False)
```

### Examples of results and Plots :
* Figuring out the most error prone package during installation
![install_plot](http://i.imgur.com/z85Nx40.png)
* Figuring out the most error prone Operating system and environment in installation of a particular package.
![os_plot](http://i.imgur.com/bajsojc.png)

### API Structure
* `run.py` : Server shall be run from this file.
* `manage.py`: Migration script to perform database migration using Flask-migrate.
* `config.py` : Application directory, SQLALCHEMY_DATABASE_URI , Secret keys etc shall be put in this file.
* `models.py` : All the models shall be defined using SQLAlchemy in this file.
* `views.py` : All the controllers, API endpoints shall be defined here.
* `__init__.py` : Defining the database object, database creation shall be done here.
* `templates` : The front end HTML files shall be kept here.
* `static` : The Bootstrap, js, CSS files, images (if any) etc shall be kept here.

**Rough Directory Structure** :
```
~/Installation_server
    |-- run.py
    |-- manage.py
    |-- config.py
    |__ /env             # Virtual Environment
    |__ /app             # Our Application        
         |-- __init__.py
         |-- views.py
         |-- models.py
         |__ /templates
             |-- 404.html
             |__ /auth
                 |-- signin.html
         |__ /static
```
**Tentative python modules** to be used :
`flask`, `flask-SQLAlchemy`, `Jinja2`, `SQLAlchemy`, `flask-migrate`, `flask-login` , 'platform', `plotly.plotly`, `plotly.graph_objs`, `requests`, `datetime`, `os`, `unittest` , `logging` etc..

### Logging and Unit testing

* **Logging** : Its always a good habbit to log the failures and errors that are taking place at server end. So, we should always keep a log for doing some debugging later on. For this, a log file is to be maintained for the application. This can be done easily by using a python module `logging`. The file shall reside in `tmp/api.log` Code snippet :
```python
import logging

from logging.handlers import RotatingFileHandler
file_handler = RotatingFileHandler('tmp/api.log', 'a', 1 * 2048 * 2048, 10)
file_handler.setFormatter(logging.Formatter('%(asctime)s %(levelname)s: %(message)s [in %(pathname)s:%(lineno)d]'))
app.logger.setLevel(logging.INFO)
file_handler.setLevel(logging.INFO)
app.logger.addHandler(file_handler)
app.logger.info('Installation script server')
```
* **Unit Testing** : Testing the code is as much profound as writing the code. And if the tests are automated, it becomes much easier to know where the application is breaking. The automated tests can be written using the pre-installed library of python `unittest`. Suppose we want to test whether the insertion in table `user_system_info` is working correctly or not, code Snippet :
```python
import os
import unittest

from config import basedir
from app import app, db
from app.models import UserSystemInfo

class TestCase(unittest.TestCase):
    def setUp(self):
        app.config['TESTING'] = True
        app.config['WTF_CSRF_ENABLED'] = False
        app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///' + os.path.join(basedir, 'test.db')
        self.app = app.test_client()
        db.create_all()

    def tearDown(self):
        db.session.remove()
        db.drop_all()

    def test_insert(self):
        data = dict(email_id="prerit2010@gmail.com", workshop_id="python",uname="Linux stijn-W150HRM 3.5.0-22-generic")
        self.app = app.test_client()
        response = self.app.post('/send_installation_data/', data=data)
        check_content_type(response.headers)
        eq_(response.status_code,201)

if __name__ == '__main__':
    unittest.main()
```

## Schedule of Deliverables 
**Community Bonding Period** : I would employ this interval for interacting with Software Carpentry community, core developers and project mentors. Read the necessary documentation, learn about organization's processes - release and otherwise - developer interactions, codes of conduct, etc. 
 
### May 25th -  June 7th 
* Analyse all the collectables from the installation-script. 
* Form a models of the database to be used at the server end. 
* Add the functionality for the student to send the collectables. 
 
### June 8th - June 21th 
* Setup the Flask API. 
* Setup [Travis](https://docs.travis-ci.com/user/languages/python) to test the code. 
* Setup the database and make connections with the API. 
* Design the models using SQLAlchemy for the database. 
 
### June 22th - July 5th 
* Setting up an endpoint where the user will make the post request. 
* Updating the installation script to make post request. 
* Testing the API and connection by a sample client script as I made [here](https://github.com/prerit2010/DemoAPI/blob/master/client.py). 
 
### July 6th - July 19th 
* Rigorous testing of the information sent by the script, and stored by server. 
* Finalize all the features of the API. 
* Bug fixes 
 
### July 20th - August 2nd 
* Analyse the outcomes of the information recorded in the database. 
* Flask admin shall also be enabled for easy handling of database. 
* Setup basic front end and return information in the form of, may be percentages. 
* Plot the conclusions using plotly. 
 
### August 3rd - August 21th 19:00 UTC 
* Testing the whole application with plots. 
* More bug fixes. 
* Code cleaning and writing documentation 
* The last 2 weeks I would want to polish my work .Test every feature rigorously before it rolls out to the users. Additionally, I will keep track of new tickets being opened and look towards patching them up as well, if they are related to faulty errors and related bugs or reporting issues. 
 
## Future work
 
Future works will include the improvements in the package installation by analysing the results generated by the API. This would lead to better management of the workshop, and help students to setup their systems in easy and less painful way. 
 
## Open Source Development Experience 
This is the first time, I am contributing to an open source organization, and feel really excited for that. My past works had all been proprietary. I worked for [Zopper](https://www.zopper.com/) as an intern, and particularly developed several RESTful API's and Dashboards using Flask Framework. Although the code is not open source, the process of development there was incredibly similar, with usage of git, issue trackers, open source tools and technologies etc. I also deployed the applications using [Ansible](https://www.ansible.com/), a very handy tool in deploying applications.  
## Academic Experience 
### About me
* I am a final year B.Tech (Computer Engineering) student in Jamia Millia Islamia University, New Delhi, India. As a part of academic experience I am inclined towards Database, Data Structures and Algorithms.

* My skill sets include : C/C++, Python - Flask, Django, Java, Android, HTML, CSS, JavaScript, MySQL, Sqlite, NoSQL - [MongoDB](https://www.mongodb.org/), REDIS, [ANSIBLE](https://www.ansible.com/).
 
* I have mostly worked with Web Development ( RESTful API's, Dashboards etc ) while working as an intern with Zopper. I worked with Google Cloud Messaging ( GCM ) to send notification and bulk notification to more than 1 million zopper application users.  
 
* I also have experience in Android Application Development. I developed an Android Application for [Litchi](http://www.litchi.co.in/), published it on PlayStore. and also a demo [FourSquare](https://github.com/prerit2010/FourSquare) application to gain more experience in android development. 
 
* Apart from this, as the academic project I worked on cryptography, and published a research paper on "Efficient Substitution Box Design using Travelling Salesman Problem and Chaos". 
 
## Why this project?
This project is concerned with the problems that students face in installing the necessary packages for a workshop. This project will enable the instructors to better understand the problems and remove the package version and other issues, so that the setup process speeds up, and students don't get stuck in just installing the packages for a long time. <br />
I have a lot of experience in developing RESTful API's and web services. This project involves development of a RESTful API and setting up a server. Working upon this, it would give me more experience towards working on APIs and python Scripts, and also a open source experience which is new and exciting for me.
 
## Appendix

Link to my opened issues : [#87](https://github.com/numfocus/gsoc/issues/87) , [#82](https://github.com/numfocus/gsoc/issues/82)

### Operating systems accessibility 

* **Laptop configuration** : Lenovo Z510 with Ubuntu 15.10 and Windows 10.
* I shall be testing the scripts on all three platforms ( Linux , Windows , OS X ). I have Linux and Windows on my Laptop, and also have access to OS X through two of my close friends' MacBook.

### Code Contribution
* As per the requirement mentioned in the project information, I developed a sample [demo](https://github.com/prerit2010/DemoAPI) flask API which takes the Operating system information and sends to the API making a POST request.
* I also created a [sample django application](https://github.com/prerit2010/SurveyMonkey-Sample) using SurveyMonkey API and displaying the plots using plotly.

### Availability
* **Time Zone :** Indian Standard Time (IST) UTC +5:30 
* 2nd Mid semester examinations start: 9th May, 2016
* 2nd Mid semester examinations end : 23rd May, 2016 (Approx.)
* My graduation (B.Tech) completes as soon as exams get over. So, after that I am available full time for the project.
* **Hours per week :** 35 hours (5 hours a day)

### Contact

|          |                               |
|----------|-------------------------------|
| Name     | Prerit Garg                   |
| Email Id | prerit2010@gmail.com          |
| Github   | https://github.com/prerit2010 |